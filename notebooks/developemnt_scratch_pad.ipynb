{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-6332cec3-b088-11ef-9750-e865382f0554</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> distributed.LocalCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">21ab60b6</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 4\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 12\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 15.21 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "</tr>\n",
       "\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-24c7f240-f784-4ff4-8cc2-c8030f812b4b</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:63748\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 4\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 12\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 15.21 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:63768\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 3\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:63771/status\" target=\"_blank\">http://127.0.0.1:63771/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 3.80 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:63751\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> C:\\Users\\suman\\AppData\\Local\\Temp\\dask-scratch-space\\worker-ibihxk68\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 1</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:63769\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 3\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:63772/status\" target=\"_blank\">http://127.0.0.1:63772/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 3.80 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:63753\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> C:\\Users\\suman\\AppData\\Local\\Temp\\dask-scratch-space\\worker-cfd6mi71\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 2</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:63767\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 3\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:63770/status\" target=\"_blank\">http://127.0.0.1:63770/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 3.80 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:63755\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> C:\\Users\\suman\\AppData\\Local\\Temp\\dask-scratch-space\\worker-xzosvj1r\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 3</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:63776\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 3\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:63777/status\" target=\"_blank\">http://127.0.0.1:63777/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 3.80 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:63757\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> C:\\Users\\suman\\AppData\\Local\\Temp\\dask-scratch-space\\worker-sfs2wzj8\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:63748' processes=4 threads=12, memory=15.21 GiB>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from dask import dataframe as dd\n",
    "from dask.distributed import Client\n",
    "import warnings\n",
    "import dask.array as da\n",
    "from tqdm import tqdm\n",
    "from dask_ml.metrics import mean_squared_error\n",
    "warnings.filterwarnings('ignore')\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformer():\n",
    "\n",
    "    \"\"\"\n",
    "    Transformer class responsible for processing data to train the CTABGANSynthesizer model\n",
    "\n",
    "    Variables:\n",
    "    1) train_data -> input dataframe\n",
    "    2) categorical_list -> list of categorical columns\n",
    "    3) mixed_dict -> dictionary of mixed columns\n",
    "    4) n_clusters -> number of modes to fit bayesian gaussian mixture (bgm) model\n",
    "    5) eps -> threshold for ignoring less prominent modes in the mixture model\n",
    "    6) ordering -> stores original ordering for modes of numeric columns\n",
    "    7) output_info -> stores dimension and output activations of columns (i.e., tanh for numeric, softmax for categorical)\n",
    "    8) output_dim -> stores the final column width of the transformed data\n",
    "    9) components -> stores the valid modes used by numeric columns\n",
    "    10) filter_arr -> stores valid indices of continuous component in mixed columns\n",
    "    11) meta -> stores column information corresponding to different data types i.e., categorical/mixed/numerical\n",
    "\n",
    "\n",
    "    Methods:\n",
    "    1) __init__() -> initializes transformer object and computes meta information of columns\n",
    "    2) get_metadata() -> builds an inventory of individual columns and stores their relevant properties\n",
    "    3) fit() -> fits the required bgm models to process the input data\n",
    "    4) transform() -> executes the transformation required to train the model\n",
    "    5) inverse_transform() -> executes the reverse transformation on data generated from the model\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_data=pd.DataFrame, categorical_list=[], mixed_dict={}, n_clusters=10, eps=0.005):\n",
    "\n",
    "        self.meta = None\n",
    "        self.train_data = train_data\n",
    "        self.categorical_columns= categorical_list\n",
    "        self.mixed_columns= mixed_dict\n",
    "        self.n_clusters = n_clusters\n",
    "        self.eps = eps\n",
    "        self.ordering = []\n",
    "        self.output_info = []\n",
    "        self.output_dim = 0\n",
    "        self.components = []\n",
    "        self.filter_arr = []\n",
    "        self.meta = self.get_metadata()\n",
    "\n",
    "    def get_metadata(self):\n",
    "\n",
    "        meta = []\n",
    "\n",
    "        for index in range(self.train_data.shape[1]):\n",
    "            column = self.train_data.iloc[:,index]\n",
    "            if index in self.categorical_columns:\n",
    "                mapper = column.value_counts().index.tolist()\n",
    "                meta.append({\n",
    "                        \"name\": index,\n",
    "                        \"type\": \"categorical\",\n",
    "                        \"size\": len(mapper),\n",
    "                        \"i2s\": mapper\n",
    "                })\n",
    "            elif index in self.mixed_columns.keys():\n",
    "                meta.append({\n",
    "                    \"name\": index,\n",
    "                    \"type\": \"mixed\",\n",
    "                    \"min\": column.min(),\n",
    "                    \"max\": column.max(),\n",
    "                    \"modal\": self.mixed_columns[index]\n",
    "                })\n",
    "            else:\n",
    "                meta.append({\n",
    "                    \"name\": self.train_data.columns[index],\n",
    "                    \"type\": \"continuous\",\n",
    "                    \"min\": float(column.min().compute()),\n",
    "                    \"max\": float(column.max().compute()),\n",
    "                })\n",
    "\n",
    "        return meta\n",
    "\n",
    "    def fit(self):\n",
    "\n",
    "        data = self.train_data\n",
    "\n",
    "        # stores the corresponding bgm models for processing numeric data\n",
    "        model = []\n",
    "\n",
    "        # iterating through column information\n",
    "        for id_, info in enumerate(self.meta):\n",
    "            if info['type'] == \"continuous\":\n",
    "                # fitting bgm model\n",
    "                gm = BayesianGaussianMixture(\n",
    "                    n_components = self.n_clusters,\n",
    "                    weight_concentration_prior_type='dirichlet_process',\n",
    "                    weight_concentration_prior=0.001, # lower values result in lesser modes being active\n",
    "                    max_iter=1,n_init=1, random_state=42)\n",
    "                print('model training has started')\n",
    "                gm.fit(data[[info['name']]])\n",
    "                print('model training completed')\n",
    "                model.append(gm)\n",
    "                # keeping only relevant modes that have higher weight than eps and are used to fit the data\n",
    "                old_comp = gm.weights_ > self.eps\n",
    "                mode_freq = (pd.Series(gm.predict(data[[info['name']]])).value_counts().keys())\n",
    "                \n",
    "                comp = []\n",
    "                for i in range(self.n_clusters):\n",
    "                    if (i in (mode_freq)) & old_comp[i]:\n",
    "                        comp.append(True)\n",
    "                    else:\n",
    "                        comp.append(False)\n",
    "                self.components.append(comp)\n",
    "                self.output_info += [(1, 'tanh'), (np.sum(comp), 'softmax')]\n",
    "                self.output_dim += 1 + np.sum(comp)\n",
    "\n",
    "            elif info['type'] == \"mixed\":\n",
    "\n",
    "                # in case of mixed columns, two bgm models are used\n",
    "                gm1 = BayesianGaussianMixture(\n",
    "                    self.n_clusters,\n",
    "                    weight_concentration_prior_type='dirichlet_process',\n",
    "                    weight_concentration_prior=0.001, max_iter=100,\n",
    "                    n_init=1,random_state=42)\n",
    "                gm2 = BayesianGaussianMixture(\n",
    "                    self.n_clusters,\n",
    "                    weight_concentration_prior_type='dirichlet_process',\n",
    "                    weight_concentration_prior=0.001, max_iter=100,\n",
    "                    n_init=1,random_state=42)\n",
    "\n",
    "                # first bgm model is fit to the entire data only for the purposes of obtaining a normalized value of any particular categorical mode\n",
    "                gm1.fit(data[:, id_].reshape([-1, 1]))\n",
    "\n",
    "                # main bgm model used to fit the continuous component and serves the same purpose as with purely numeric columns\n",
    "                filter_arr = []\n",
    "                for element in data[:, id_]:\n",
    "                    if element not in info['modal']:\n",
    "                        filter_arr.append(True)\n",
    "                    else:\n",
    "                        filter_arr.append(False)\n",
    "                self.filter_arr.append(filter_arr)\n",
    "\n",
    "                gm2.fit(data[:, id_][filter_arr].reshape([-1, 1]))\n",
    "\n",
    "                model.append((gm1,gm2))\n",
    "\n",
    "                # similarly keeping only relevant modes with higher weight than eps and are used to fit strictly continuous data\n",
    "                old_comp = gm2.weights_ > self.eps\n",
    "                mode_freq = (pd.Series(gm2.predict(data[:, id_][filter_arr].reshape([-1, 1]))).value_counts().keys())\n",
    "                comp = []\n",
    "\n",
    "                for i in range(self.n_clusters):\n",
    "                    if (i in (mode_freq)) & old_comp[i]:\n",
    "                        comp.append(True)\n",
    "                    else:\n",
    "                        comp.append(False)\n",
    "\n",
    "                self.components.append(comp)\n",
    "\n",
    "                # modes of the categorical component are appended to modes produced by the main bgm model\n",
    "                self.output_info += [(1, 'tanh'), (np.sum(comp) + len(info['modal']), 'softmax')]\n",
    "                self.output_dim += 1 + np.sum(comp) + len(info['modal'])\n",
    "\n",
    "            else:\n",
    "                # in case of categorical columns, bgm model is ignored\n",
    "                model.append(None)\n",
    "                self.components.append(None)\n",
    "                self.output_info += [(info['size'], 'softmax')]\n",
    "                self.output_dim += info['size']\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def transform(self, data):\n",
    "\n",
    "        # stores the transformed values\n",
    "        values = []\n",
    "\n",
    "        # used for accessing filter_arr for transforming mixed columns\n",
    "        mixed_counter = 0\n",
    "\n",
    "        # iterating through column information\n",
    "        for id_, info in enumerate(self.meta):\n",
    "            if info['type'] == \"continuous\":\n",
    "                # mode-specific normalization occurs here\n",
    "                lengths = []\n",
    "                for i in tqdm(list(data.partitions)):\n",
    "                    lengths.append(len(i))\n",
    "                current = data[[info['name']]].to_dask_array(lengths=lengths)\n",
    "                # means and stds of the modes are obtained from the corresponding fitted bgm model\n",
    "                means = self.model[id_].means_.reshape((1, self.n_clusters))\n",
    "                stds = da.sqrt(self.model[id_].covariances_).reshape((1, self.n_clusters))\n",
    "                # values are then normalized and stored for all modes\n",
    "                features = da.empty(shape=(len(current),self.n_clusters))\n",
    "                # note 4 is a multiplier to ensure values lie between -1 to 1 but this is not always guaranteed\n",
    "                \n",
    "                features = (current - means) / (4 * stds)\n",
    "                \n",
    "                # number of distict modes\n",
    "                n_opts = sum(self.components[id_])\n",
    "                # storing the mode for each data point by sampling from the probability mass distribution across all modes based on fitted bgm model\n",
    "                opt_sel = da.zeros(len(data), dtype='int')\n",
    "                print('prediction started')\n",
    "                current = current\n",
    "                probs = self.model[id_].predict_proba(current)\n",
    "                print('prediction complete')\n",
    "                probs = probs[:, self.components[id_]]\n",
    "\n",
    "                probs = probs + 1e-6\n",
    "                probs = probs / da.broadcast_to(probs.sum(axis=1).reshape((len(probs), 1)), probs.shape)\n",
    "                opt_sel = (probs.cumsum(axis=1) <= da.broadcast_to(da.random.random(len(probs)).reshape((len(probs), 1)), probs.shape)).sum(axis=1)\n",
    "                # creating a one-hot-encoding for the corresponding selected modes\n",
    "                \n",
    "                probs_onehot = da.eye(probs.shape[1], chunks='auto')[opt_sel]\n",
    "                # obtaining the normalized values based on the appropriately selected mode and clipping to ensure values are within (-1,1)\n",
    "                features = features[:, self.components[id_]]\n",
    "                features = (features * probs_onehot).sum(axis=1).reshape([-1, 1])\n",
    "                features = da.clip(features, -.99, .99)\n",
    "\n",
    "                # re-ordering the one-hot-encoding of modes in descending order as per their frequency of being selected\n",
    "                re_ordered_phot = da.zeros_like(probs_onehot)\n",
    "                col_sums = probs_onehot.sum(axis=0).compute()\n",
    "                n = probs_onehot.shape[1]\n",
    "                largest_indices = np.argsort(-1*col_sums)[:n]\n",
    "                for id,val in tqdm(enumerate(largest_indices)):\n",
    "                    re_ordered_phot[:,id] = probs_onehot[:,val]\n",
    "\n",
    "                # storing the original ordering for invoking inverse transform\n",
    "                self.ordering.append(largest_indices)\n",
    "\n",
    "                # storing transformed numeric column represented as normalized values and corresponding modes\n",
    "                values += [features, re_ordered_phot]\n",
    "\n",
    "            elif info['type'] == \"mixed\":\n",
    "\n",
    "                # means and standard deviation of modes obtained from the first fitted bgm model\n",
    "                means_0 = self.model[id_][0].means_.reshape([-1])\n",
    "                stds_0 = np.sqrt(self.model[id_][0].covariances_).reshape([-1])\n",
    "\n",
    "                # list to store relevant bgm modes for categorical components\n",
    "                zero_std_list = []\n",
    "\n",
    "                # means and stds needed to normalize relevant categorical components\n",
    "                means_needed = []\n",
    "                stds_needed = []\n",
    "\n",
    "                # obtaining the closest bgm mode to the categorical component\n",
    "                for mode in info['modal']:\n",
    "                    # skipped for mode representing missing values\n",
    "                    if mode!=-9999999:\n",
    "                        dist = []\n",
    "                        for idx,val in enumerate(list(means_0.flatten())):\n",
    "                            dist.append(abs(mode-val))\n",
    "                        index_min = np.argmin(np.array(dist))\n",
    "                        zero_std_list.append(index_min)\n",
    "                    else: continue\n",
    "\n",
    "\n",
    "                # stores the appropriate normalized value of categorical modes\n",
    "                mode_vals = []\n",
    "\n",
    "                # based on the means and stds of the chosen modes for categorical components, their respective values are similarly normalized\n",
    "                for idx in zero_std_list:\n",
    "                    means_needed.append(means_0[idx])\n",
    "                    stds_needed.append(stds_0[idx])\n",
    "\n",
    "                for i,j,k in zip(info['modal'],means_needed,stds_needed):\n",
    "                    this_val  = np.clip(((i - j) / (4*k)), -.99, .99)\n",
    "                    mode_vals.append(this_val)\n",
    "\n",
    "                # for categorical modes representing missing values, the normalized value associated is simply 0\n",
    "                if -9999999 in info[\"modal\"]:\n",
    "                    mode_vals.append(0)\n",
    "\n",
    "                # transforming continuous component of mixed columns similar to purely numeric columns using second fitted bgm model\n",
    "                current = current.reshape([-1, 1])\n",
    "                filter_arr = self.filter_arr[mixed_counter]\n",
    "                current = current[filter_arr]\n",
    "\n",
    "                means = self.model[id_][1].means_.reshape((1, self.n_clusters))\n",
    "                stds = np.sqrt(self.model[id_][1].covariances_).reshape((1, self.n_clusters))\n",
    "\n",
    "                features = np.empty(shape=(len(current),self.n_clusters))\n",
    "                features = (current - means) / (4 * stds)\n",
    "\n",
    "                n_opts = sum(self.components[id_])\n",
    "                probs = self.model[id_][1].predict_proba(current.reshape([-1, 1]))\n",
    "                probs = probs[:, self.components[id_]]\n",
    "\n",
    "                opt_sel = np.zeros(len(current), dtype='int')\n",
    "                for i in range(len(current)):\n",
    "                    pp = probs[i] + 1e-6\n",
    "                    pp = pp / sum(pp)\n",
    "                    opt_sel[i] = np.random.choice(np.arange(n_opts), p=pp)\n",
    "\n",
    "                idx = np.arange((len(features)))\n",
    "                features = features[:, self.components[id_]]\n",
    "                features = features[idx, opt_sel].reshape([-1, 1])\n",
    "                features = np.clip(features, -.99, .99)\n",
    "\n",
    "                probs_onehot = np.zeros_like(probs)\n",
    "                probs_onehot[np.arange(len(probs)), opt_sel] = 1\n",
    "\n",
    "                # additional modes are appended to represent categorical component\n",
    "                extra_bits = np.zeros([len(current), len(info['modal'])])\n",
    "                temp_probs_onehot = np.concatenate([extra_bits,probs_onehot], axis = 1)\n",
    "\n",
    "                # storing the final normalized value and one-hot-encoding of selected modes\n",
    "                final = np.zeros([len(data), 1 + probs_onehot.shape[1] + len(info['modal'])])\n",
    "\n",
    "                # iterates through only the continuous component\n",
    "                features_curser = 0\n",
    "\n",
    "                for idx, val in enumerate(data[:, id_]):\n",
    "\n",
    "                    if val in info['modal']:\n",
    "                        # dealing with the modes of categorical component\n",
    "                        category_ = list(map(info['modal'].index, [val]))[0]\n",
    "                        final[idx, 0] = mode_vals[category_]\n",
    "                        final[idx, (category_+1)] = 1\n",
    "\n",
    "                    else:\n",
    "                        # dealing with the modes of continuous component\n",
    "                        final[idx, 0] = features[features_curser]\n",
    "                        final[idx, (1+len(info['modal'])):] = temp_probs_onehot[features_curser][len(info['modal']):]\n",
    "                        features_curser = features_curser + 1\n",
    "\n",
    "                # re-ordering the one-hot-encoding of modes in descending order as per their frequency of being selected\n",
    "                just_onehot = final[:,1:]\n",
    "                re_ordered_jhot= np.zeros_like(just_onehot)\n",
    "                n = just_onehot.shape[1]\n",
    "                col_sums = just_onehot.sum(axis=0)\n",
    "                largest_indices = np.argsort(-1*col_sums)[:n]\n",
    "\n",
    "                for id,val in enumerate(largest_indices):\n",
    "                      re_ordered_jhot[:,id] = just_onehot[:,val]\n",
    "\n",
    "                final_features = final[:,0].reshape([-1, 1])\n",
    "\n",
    "                # storing the original ordering for invoking inverse transform\n",
    "                self.ordering.append(largest_indices)\n",
    "\n",
    "                values += [final_features, re_ordered_jhot]\n",
    "\n",
    "                mixed_counter = mixed_counter + 1\n",
    "\n",
    "            else:\n",
    "                # for categorical columns, standard one-hot-encoding is applied where categories are in descending order of frequency by default\n",
    "                self.ordering.append(None)\n",
    "                col_t = np.zeros([len(data), info['size']])\n",
    "                idx = list(map(info['i2s'].index, current))\n",
    "                col_t[np.arange(len(data)), idx] = 1\n",
    "                values.append(col_t)\n",
    "\n",
    "        return np.concatenate(values, axis=1)\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "\n",
    "        # stores the final inverse transformed generated data\n",
    "        data_t = da.zeros([len(data), len(self.meta)])\n",
    "\n",
    "        # used to iterate through the columns of the raw generated data\n",
    "        st = 0\n",
    "\n",
    "        # iterating through original column information\n",
    "        for id_, info in enumerate(self.meta):\n",
    "            if info['type'] == \"continuous\":\n",
    "\n",
    "                # obtaining the generated normalized values and clipping for stability\n",
    "                u = data[:, st]\n",
    "                u = da.clip(u, -1, 1)\n",
    "\n",
    "                # obtaining the one-hot-encoding of the modes representing the normalized values\n",
    "                v = data[:, st + 1:st + 1 + np.sum(self.components[id_])]\n",
    "\n",
    "                # re-ordering the modes as per their original ordering\n",
    "                order = self.ordering[id_]\n",
    "                v_re_ordered = da.zeros_like(v)\n",
    "                for id,val in enumerate(order):\n",
    "                    v_re_ordered[:,val] = v[:,id]\n",
    "                v = v_re_ordered\n",
    "\n",
    "                # ensuring un-used modes are represented with -100 such that they can be ignored when computing argmax\n",
    "                v_t = da.ones((data.shape[0], self.n_clusters)) * -100\n",
    "                v_t[:, self.components[id_]] = v\n",
    "                v = v_t\n",
    "\n",
    "                # obtaining approriate means and stds as per the appropriately selected mode for each data point based on fitted bgm model\n",
    "                means = self.model[id_].means_.reshape([-1])\n",
    "                stds = da.sqrt(self.model[id_].covariances_).reshape([-1])\n",
    "                p_argmax = da.argmax(v, axis=1)\n",
    "                std_t = stds[p_argmax]\n",
    "                mean_t = means[p_argmax]\n",
    "\n",
    "                # executing the inverse transformation\n",
    "                tmp = u * 4 * std_t + mean_t\n",
    "\n",
    "                data_t[:, id_] = tmp\n",
    "\n",
    "                # moving to the next set of columns in the raw generated data in correspondance to original column information\n",
    "                st += 1 + np.sum(self.components[id_])\n",
    "\n",
    "            elif info['type'] == \"mixed\":\n",
    "\n",
    "                # obtaining the generated normalized values and corresponding modes\n",
    "                u = data[:, st]\n",
    "                u = np.clip(u, -1, 1)\n",
    "                full_v = data[:,(st+1):(st+1)+len(info['modal'])+np.sum(self.components[id_])]\n",
    "\n",
    "                # re-ordering the modes as per their original ordering\n",
    "                order = self.ordering[id_]\n",
    "                full_v_re_ordered = np.zeros_like(full_v)\n",
    "                for id,val in enumerate(order):\n",
    "                    full_v_re_ordered[:,val] = full_v[:,id]\n",
    "                full_v = full_v_re_ordered\n",
    "\n",
    "                # modes of categorical component\n",
    "                mixed_v = full_v[:,:len(info['modal'])]\n",
    "\n",
    "                # modes of continuous component\n",
    "                v = full_v[:,-np.sum(self.components[id_]):]\n",
    "\n",
    "                # similarly ensuring un-used modes are represented with -100 to be ignored while computing argmax\n",
    "                v_t = np.ones((data.shape[0], self.n_clusters)) * -100\n",
    "                v_t[:, self.components[id_]] = v\n",
    "                v = np.concatenate([mixed_v,v_t], axis=1)\n",
    "                p_argmax = np.argmax(v, axis=1)\n",
    "\n",
    "                # obtaining the means and stds of the continuous component using second fitted bgm model\n",
    "                means = self.model[id_][1].means_.reshape([-1])\n",
    "                stds = np.sqrt(self.model[id_][1].covariances_).reshape([-1])\n",
    "\n",
    "                # used to store the inverse-transformed data points\n",
    "                result = np.zeros_like(u)\n",
    "\n",
    "                for idx in range(len(data)):\n",
    "                    # in case of categorical mode being selected, the mode value itself is simply assigned\n",
    "                    if p_argmax[idx] < len(info['modal']):\n",
    "                        argmax_value = p_argmax[idx]\n",
    "                        result[idx] = float(list(map(info['modal'].__getitem__, [argmax_value]))[0])\n",
    "                    else:\n",
    "                        # in case of continuous mode being selected, similar inverse-transform for purely numeric values is applied\n",
    "                        std_t = stds[(p_argmax[idx]-len(info['modal']))]\n",
    "                        mean_t = means[(p_argmax[idx]-len(info['modal']))]\n",
    "                        result[idx] = u[idx] * 4 * std_t + mean_t\n",
    "\n",
    "                data_t[:, id_] = result\n",
    "\n",
    "                st += 1 + np.sum(self.components[id_]) + len(info['modal'])\n",
    "\n",
    "            else:\n",
    "                # reversing one hot encoding back to label encoding for categorical columns\n",
    "                current = data[:, st:st + info['size']]\n",
    "                idx = np.argmax(current, axis=1)\n",
    "                data_t[:, id_] = list(map(info['i2s'].__getitem__, idx))\n",
    "                st += info['size']\n",
    "        return data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dd.read_csv(\"../data/raw/Credit.csv\", blocksize=2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = dd.read_parquet(\"../data/scaled/\", blocksize=4000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(data.partitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training has started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask_expr._collection.DataFrame'>\n",
      "<class 'dask.array.core.Array'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: value array of shape (nan,) could not be broadcast to indexing result of shape (49842,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m transformer \u001b[38;5;241m=\u001b[39m DataTransformer(train_data\u001b[38;5;241m=\u001b[39mdata[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmount\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 93\u001b[0m, in \u001b[0;36mDataTransformer.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m gm \u001b[38;5;241m=\u001b[39m BayesianGaussianMixture(\n\u001b[0;32m     88\u001b[0m     n_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters,\n\u001b[0;32m     89\u001b[0m     weight_concentration_prior_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirichlet_process\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     90\u001b[0m     weight_concentration_prior\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;66;03m# lower values result in lesser modes being active\u001b[39;00m\n\u001b[0;32m     91\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel training has started\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[43mgm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel training completed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     95\u001b[0m model\u001b[38;5;241m.\u001b[39mappend(gm)\n",
      "File \u001b[1;32mc:\\Users\\suman\\data\\BD_MLE_assignment\\venv\\Lib\\site-packages\\sklearn\\mixture\\_base.py:190\u001b[0m, in \u001b[0;36mBaseMixture.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Estimate model parameters with the EM algorithm.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03mThe method fits the model ``n_init`` times and sets the parameters with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m    The fitted mixture.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# parameters are validated in fit_predict\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\suman\\data\\BD_MLE_assignment\\venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\suman\\data\\BD_MLE_assignment\\venv\\Lib\\site-packages\\sklearn\\mixture\\_base.py:255\u001b[0m, in \u001b[0;36mBaseMixture.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_iter \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    254\u001b[0m     prev_lower_bound \u001b[38;5;241m=\u001b[39m lower_bound\n\u001b[1;32m--> 255\u001b[0m     log_prob_norm, log_resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_m_step(X, log_resp)\n\u001b[0;32m    257\u001b[0m     lower_bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_lower_bound(log_resp, log_prob_norm)\n",
      "File \u001b[1;32mc:\\Users\\suman\\data\\BD_MLE_assignment\\venv\\Lib\\site-packages\\sklearn\\mixture\\_base.py:314\u001b[0m, in \u001b[0;36mBaseMixture._e_step\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_e_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    299\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"E step.\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \n\u001b[0;32m    301\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m        the point of each sample in X.\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 314\u001b[0m     log_prob_norm, log_resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_estimate_log_prob_resp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(log_prob_norm), log_resp\n",
      "File \u001b[1;32mc:\\Users\\suman\\data\\BD_MLE_assignment\\venv\\Lib\\site-packages\\sklearn\\mixture\\_base.py:534\u001b[0m, in \u001b[0;36mBaseMixture._estimate_log_prob_resp\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_estimate_log_prob_resp\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    516\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Estimate log probabilities and responsibilities for each sample.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \n\u001b[0;32m    518\u001b[0m \u001b[38;5;124;03m    Compute the log probabilities, weighted log probabilities per\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;124;03m        logarithm of the responsibilities\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 534\u001b[0m     weighted_log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_estimate_weighted_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m     log_prob_norm \u001b[38;5;241m=\u001b[39m logsumexp(weighted_log_prob, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;66;03m# ignore underflow\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\suman\\data\\BD_MLE_assignment\\venv\\Lib\\site-packages\\sklearn\\mixture\\_base.py:487\u001b[0m, in \u001b[0;36mBaseMixture._estimate_weighted_log_prob\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_estimate_weighted_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    477\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Estimate the weighted log-probabilities, log P(X | Z) + log weights.\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \n\u001b[0;32m    479\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;124;03m    weighted_log_prob : array, shape (n_samples, n_component)\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_estimate_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimate_log_weights()\n",
      "File \u001b[1;32mc:\\Users\\suman\\data\\BD_MLE_assignment\\venv\\Lib\\site-packages\\sklearn\\mixture\\_bayesian_mixture.py:774\u001b[0m, in \u001b[0;36mBayesianGaussianMixture._estimate_log_prob\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    771\u001b[0m _, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    772\u001b[0m \u001b[38;5;66;03m# We remove `n_features * np.log(self.degrees_of_freedom_)` because\u001b[39;00m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;66;03m# the precision matrix is normalized\u001b[39;00m\n\u001b[1;32m--> 774\u001b[0m log_gauss \u001b[38;5;241m=\u001b[39m \u001b[43m_estimate_log_gaussian_prob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeans_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecisions_cholesky_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariance_type\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m n_features \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegrees_of_freedom_)\n\u001b[0;32m    778\u001b[0m log_lambda \u001b[38;5;241m=\u001b[39m n_features \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2.0\u001b[39m) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\n\u001b[0;32m    779\u001b[0m     digamma(\n\u001b[0;32m    780\u001b[0m         \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    784\u001b[0m )\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_gauss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (log_lambda \u001b[38;5;241m-\u001b[39m n_features \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_precision_)\n",
      "File \u001b[1;32mc:\\Users\\suman\\data\\BD_MLE_assignment\\venv\\Lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:494\u001b[0m, in \u001b[0;36m_estimate_log_gaussian_prob\u001b[1;34m(X, means, precisions_chol, covariance_type)\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, (mu, prec_chol) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(means, precisions_chol)):\n\u001b[0;32m    493\u001b[0m         y \u001b[38;5;241m=\u001b[39m da\u001b[38;5;241m.\u001b[39mdot(X, prec_chol) \u001b[38;5;241m-\u001b[39m da\u001b[38;5;241m.\u001b[39mdot(mu, prec_chol)\n\u001b[1;32m--> 494\u001b[0m         \u001b[43mlog_prob\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m da\u001b[38;5;241m.\u001b[39msum(da\u001b[38;5;241m.\u001b[39msquare(y), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m covariance_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtied\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    497\u001b[0m     log_prob \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((n_samples, n_components))\n",
      "File \u001b[1;32mc:\\Users\\suman\\data\\BD_MLE_assignment\\venv\\Lib\\site-packages\\dask\\array\\core.py:1979\u001b[0m, in \u001b[0;36mArray.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1976\u001b[0m value \u001b[38;5;241m=\u001b[39m asanyarray(value)\n\u001b[0;32m   1978\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetitem-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m tokenize(\u001b[38;5;28mself\u001b[39m, key, value)\n\u001b[1;32m-> 1979\u001b[0m dsk \u001b[38;5;241m=\u001b[39m \u001b[43msetitem_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1981\u001b[0m meta \u001b[38;5;241m=\u001b[39m meta_from_array(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_meta)\n\u001b[0;32m   1982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(meta):\n",
      "File \u001b[1;32mc:\\Users\\suman\\data\\BD_MLE_assignment\\venv\\Lib\\site-packages\\dask\\array\\slicing.py:1790\u001b[0m, in \u001b[0;36msetitem_array\u001b[1;34m(out_name, array, indices, value)\u001b[0m\n\u001b[0;32m   1788\u001b[0m         non_broadcast_dimensions\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[0;32m   1789\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1790\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1791\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape mismatch: value array of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1792\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not be broadcast to indexing result of shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1793\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(implied_shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1794\u001b[0m         )\n\u001b[0;32m   1796\u001b[0m \u001b[38;5;66;03m# Translate chunks tuple to a set of array locations in product\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m \u001b[38;5;66;03m# order\u001b[39;00m\n\u001b[0;32m   1798\u001b[0m chunks \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mchunks\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: value array of shape (nan,) could not be broadcast to indexing result of shape (49842,)"
     ]
    }
   ],
   "source": [
    "transformer = DataTransformer(train_data=data[['Amount']])\n",
    "transformer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20160/20160 [27:00<00:00, 12.44it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction started\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 74.9 GiB for an array with shape (1004814720, 10) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[278], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m dd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/scaled/\u001b[39m\u001b[38;5;124m\"\u001b[39m, blocksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4000000\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread file\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAmount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m amt \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39minverse_transform(a)\n",
      "Cell \u001b[1;32mIn[273], line 197\u001b[0m, in \u001b[0;36mDataTransformer.transform\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction started\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    196\u001b[0m current \u001b[38;5;241m=\u001b[39m current\n\u001b[1;32m--> 197\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mid_\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction complete\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    199\u001b[0m probs \u001b[38;5;241m=\u001b[39m probs[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents[id_]]\n",
      "File \u001b[1;32mc:\\Users\\suman\\data\\BD_MLE_assignment\\venv\\Lib\\site-packages\\sklearn\\mixture\\_base.py:411\u001b[0m, in \u001b[0;36mBaseMixture.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    409\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    410\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 411\u001b[0m _, log_resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_estimate_log_prob_resp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mexp(log_resp)\n",
      "File \u001b[1;32mc:\\Users\\suman\\data\\BD_MLE_assignment\\venv\\Lib\\site-packages\\sklearn\\mixture\\_base.py:534\u001b[0m, in \u001b[0;36mBaseMixture._estimate_log_prob_resp\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_estimate_log_prob_resp\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    516\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Estimate log probabilities and responsibilities for each sample.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \n\u001b[0;32m    518\u001b[0m \u001b[38;5;124;03m    Compute the log probabilities, weighted log probabilities per\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;124;03m        logarithm of the responsibilities\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 534\u001b[0m     weighted_log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_estimate_weighted_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m     log_prob_norm \u001b[38;5;241m=\u001b[39m logsumexp(weighted_log_prob, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;66;03m# ignore underflow\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\suman\\data\\BD_MLE_assignment\\venv\\Lib\\site-packages\\sklearn\\mixture\\_base.py:487\u001b[0m, in \u001b[0;36mBaseMixture._estimate_weighted_log_prob\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_estimate_weighted_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    477\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Estimate the weighted log-probabilities, log P(X | Z) + log weights.\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \n\u001b[0;32m    479\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;124;03m    weighted_log_prob : array, shape (n_samples, n_component)\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_estimate_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimate_log_weights()\n",
      "File \u001b[1;32mc:\\Users\\suman\\data\\BD_MLE_assignment\\venv\\Lib\\site-packages\\sklearn\\mixture\\_bayesian_mixture.py:774\u001b[0m, in \u001b[0;36mBayesianGaussianMixture._estimate_log_prob\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    771\u001b[0m _, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    772\u001b[0m \u001b[38;5;66;03m# We remove `n_features * np.log(self.degrees_of_freedom_)` because\u001b[39;00m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;66;03m# the precision matrix is normalized\u001b[39;00m\n\u001b[1;32m--> 774\u001b[0m log_gauss \u001b[38;5;241m=\u001b[39m \u001b[43m_estimate_log_gaussian_prob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeans_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecisions_cholesky_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariance_type\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m n_features \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegrees_of_freedom_)\n\u001b[0;32m    778\u001b[0m log_lambda \u001b[38;5;241m=\u001b[39m n_features \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2.0\u001b[39m) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\n\u001b[0;32m    779\u001b[0m     digamma(\n\u001b[0;32m    780\u001b[0m         \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    784\u001b[0m )\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_gauss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (log_lambda \u001b[38;5;241m-\u001b[39m n_features \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_precision_)\n",
      "File \u001b[1;32mc:\\Users\\suman\\data\\BD_MLE_assignment\\venv\\Lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:488\u001b[0m, in \u001b[0;36m_estimate_log_gaussian_prob\u001b[1;34m(X, means, precisions_chol, covariance_type)\u001b[0m\n\u001b[0;32m    485\u001b[0m log_det \u001b[38;5;241m=\u001b[39m _compute_log_det_cholesky(precisions_chol, covariance_type, n_features)\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m covariance_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 488\u001b[0m     log_prob \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, (mu, prec_chol) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(means, precisions_chol)):\n\u001b[0;32m    490\u001b[0m         y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X, prec_chol) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(mu, prec_chol)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 74.9 GiB for an array with shape (1004814720, 10) and data type float64"
     ]
    }
   ],
   "source": [
    "#data = dd.read_parquet(\"../data/scaled/\", blocksize=4000000)\n",
    "print('read file')\n",
    "a = transformer.transform(data[['Amount']])\n",
    "print('transformed')\n",
    "amt = transformer.inverse_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(14133.676855987542)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(data[['Amount']].to_dask_array(lengths=(1e5,)), amt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(21493.68217991699)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(data[['Amount']].to_dask_array(lengths=(1e5,)), amt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
